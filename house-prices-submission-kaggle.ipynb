{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Academic Integrity and Learning Statement\n",
    "\n",
    "By submitting my work, I confirm that:\n",
    "\n",
    "1. The code, analysis, and documentation in this notebook are my own work and reflect my own understanding.\n",
    "2. I am prepared to explain all code and analysis included in this submission.\n",
    "\n",
    "If I used assistance (e.g., AI tools, tutors, or other resources), I have:\n",
    "\n",
    "- Clearly documented where and how external tools or resources were used in my solution.\n",
    "- Included a copy of the interaction (e.g., AI conversation or tutoring notes) in an appendix.\n",
    "\n",
    "I acknowledge that:\n",
    "\n",
    "- I may be asked to explain any part of my code or analysis during evaluation.\n",
    "- Misrepresenting assisted work as my own constitutes academic dishonesty and undermines my learning."
   ],
   "id": "71e8cdf0751690d6"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-30T04:03:26.658512Z",
     "start_time": "2025-06-30T04:03:26.654347Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import subprocess\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import optuna\n",
    "import mlflow\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import platform"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T04:03:29.188Z",
     "start_time": "2025-06-30T04:03:29.143910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Enable auto-reload extension\n",
    "%load_ext autoreload\n",
    "# Automatically reload all modules before executing code\n",
    "%autoreload 2"
   ],
   "id": "c46da9c6fd73de53",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T04:03:33.105157Z",
     "start_time": "2025-06-30T04:03:32.488012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import base_utils_logging\n",
    "import proj_utils_data_loader\n",
    "import proj_configs\n",
    "import proj_utils\n",
    "import proj_utils_feat_engg\n",
    "import proj_utils_plots\n",
    "import proj_utils_model"
   ],
   "id": "88ba6ac1d373ffce",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T04:03:35.735718Z",
     "start_time": "2025-06-30T04:03:35.698262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")"
   ],
   "id": "f5129035565a3994",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T04:03:36.915496Z",
     "start_time": "2025-06-30T04:03:36.851892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check software specs\n",
    "dict_sw_version = {\n",
    "    'python': os.popen('python --version').read().strip(),\n",
    "    'numpy': np.__version__,\n",
    "    'pandas': pd.__version__,\n",
    "    'optuna': optuna.__version__,\n",
    "    'mlflow': mlflow.__version__,\n",
    "}\n",
    "\n",
    "for key, value in dict_sw_version.items():\n",
    "    print(f'{proj_utils_plots.beautify(key, 1)} version is: {proj_utils_plots.beautify(value)}')\n"
   ],
   "id": "6d24b286ccfc7d22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m\u001B[32mpython\u001B[0m version is: \u001B[1m\u001B[35mPython 3.11.13\u001B[0m\n",
      "\u001B[1m\u001B[32mnumpy\u001B[0m version is: \u001B[1m\u001B[35m1.26.4\u001B[0m\n",
      "\u001B[1m\u001B[32mpandas\u001B[0m version is: \u001B[1m\u001B[35m2.2.3\u001B[0m\n",
      "\u001B[1m\u001B[32moptuna\u001B[0m version is: \u001B[1m\u001B[35m4.4.0\u001B[0m\n",
      "\u001B[1m\u001B[32mmlflow\u001B[0m version is: \u001B[1m\u001B[35m2.18.0\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T04:03:45.808137Z",
     "start_time": "2025-06-30T04:03:45.522435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check hardware specs\n",
    "def get_mac_gpu_info():\n",
    "    try:\n",
    "        # Get system information about GPU\n",
    "        result = subprocess.run(['system_profiler', 'SPDisplaysDataType'],\n",
    "                              capture_output=True, text=True)\n",
    "        return result.stdout\n",
    "    except Exception as e:\n",
    "        return f\"Error getting GPU info: {e}\"\n",
    "\n",
    "# Check CPU cores\n",
    "print(f'CPU cores available to use: {proj_utils_plots.beautify(str(multiprocessing.cpu_count()))}')\n",
    "\n",
    "# Check MPS availability\n",
    "print(\"TensorFlow GPU devices:\", proj_utils_plots.beautify(tf.config.list_physical_devices('GPU')))\n",
    "print(f\"Processor: {proj_utils_plots.beautify(platform.processor())}\")\n",
    "print(f\"Machine: {proj_utils_plots.beautify(platform.machine())}\")\n",
    "\n",
    "print(\"PyTorch MPS (Metal) Status:\")\n",
    "print(f\"MPS available: {proj_utils_plots.beautify(torch.backends.mps.is_available())}\")\n",
    "print(f\"MPS built: {proj_utils_plots.beautify(str(torch.backends.mps.is_built()))}\")\n",
    "\n",
    "# Get detailed GPU information\n",
    "print(\"\\nDetailed GPU Information:\")\n",
    "print(get_mac_gpu_info())"
   ],
   "id": "337330b589c6a835",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU cores available to use: \u001B[1m\u001B[35m10\u001B[0m\n",
      "TensorFlow GPU devices: \u001B[1m\u001B[35m[]\u001B[0m\n",
      "Processor: \u001B[1m\u001B[35marm\u001B[0m\n",
      "Machine: \u001B[1m\u001B[35marm64\u001B[0m\n",
      "PyTorch MPS (Metal) Status:\n",
      "MPS available: \u001B[1m\u001B[35mTrue\u001B[0m\n",
      "MPS built: \u001B[1m\u001B[35mTrue\u001B[0m\n",
      "\n",
      "Detailed GPU Information:\n",
      "Graphics/Displays:\n",
      "\n",
      "    Apple M4:\n",
      "\n",
      "      Chipset Model: Apple M4\n",
      "      Type: GPU\n",
      "      Bus: Built-In\n",
      "      Total Number of Cores: 10\n",
      "      Vendor: Apple (0x106b)\n",
      "      Metal Support: Metal 3\n",
      "      Displays:\n",
      "        Color LCD:\n",
      "          Display Type: Built-in Liquid Retina XDR Display\n",
      "          Resolution: 3024 x 1964 Retina\n",
      "          Main Display: Yes\n",
      "          Mirror: Off\n",
      "          Online: Yes\n",
      "          Automatically Adjust Brightness: Yes\n",
      "          Connection Type: Internal\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T04:09:54.100118Z",
     "start_time": "2025-06-30T04:09:54.048294Z"
    }
   },
   "cell_type": "code",
   "source": "base_utils_logging.setup_logging()",
   "id": "a31b0f710678697c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T04:09:55.635677Z",
     "start_time": "2025-06-30T04:09:55.579986Z"
    }
   },
   "cell_type": "code",
   "source": "base_utils_logging.logger.info('Starting the application')",
   "id": "4e9d276c1b24d439",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T04:10:28.444040Z",
     "start_time": "2025-06-30T04:10:28.349672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_raw_train = proj_utils_data_loader.load_data(proj_configs.TRAIN_FILE)\n",
    "df_raw_test = proj_utils_data_loader.load_data(proj_configs.TEST_FILE)\n",
    "df_raw_train.shape, df_raw_test.shape"
   ],
   "id": "eed9d9da9617bed0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 81), (1459, 80))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T04:10:29.723649Z",
     "start_time": "2025-06-30T04:10:29.674713Z"
    }
   },
   "cell_type": "code",
   "source": "df_raw_train.sample(3)",
   "id": "d3f3a25cad6101e2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "85    86          60       RL        121.0    16059   Pave   NaN      Reg   \n",
       "352  353          50       RL         60.0     9084   Pave   NaN      Reg   \n",
       "495  496          30  C (all)         60.0     7879   Pave   NaN      Reg   \n",
       "\n",
       "    LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "85          Lvl    AllPub  ...        0    NaN   NaN         NaN       0   \n",
       "352         Lvl    AllPub  ...        0    NaN   NaN         NaN       0   \n",
       "495         Lvl    AllPub  ...        0    NaN  GdWo         NaN       0   \n",
       "\n",
       "    MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "85       4   2006        WD         Normal     260000  \n",
       "352      3   2008     ConLw         Normal      95000  \n",
       "495     11   2009        WD        Abnorml      34900  \n",
       "\n",
       "[3 rows x 81 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>121.0</td>\n",
       "      <td>16059</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>353</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9084</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>ConLw</td>\n",
       "      <td>Normal</td>\n",
       "      <td>95000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>30</td>\n",
       "      <td>C (all)</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7879</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdWo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>34900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 81 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T04:10:31.300272Z",
     "start_time": "2025-06-30T04:10:31.259518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO: uncomment and comment below insignificant col list\n",
    "# insignificant_cols = ['Order', 'PID']\n",
    "insignificant_cols = ['Id']\n",
    "target_col = 'SalePrice'\n",
    "ignorables_cols = insignificant_cols + [target_col]\n",
    "ordinal_cols = ['LotShape', 'Utilities', 'LandSlope', 'OverallQual', 'OverallCond', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']\n",
    "temporal_cols_name_pattern = ['Yr', 'Year']"
   ],
   "id": "6edf5a9a26a9e843",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T04:10:32.749708Z",
     "start_time": "2025-06-30T04:10:32.684331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_raw_all, df_raw_target = proj_utils_data_loader.merge_train_test_data(df_raw_train, df_raw_test, insignificant_cols, target_col)\n",
    "df_raw_all.shape, df_raw_target.shape"
   ],
   "id": "654f96a21abe775e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2919, 80), (1460,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "cf91a17b78185573",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "23d92e996dde6775",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T04:11:41.588866Z",
     "start_time": "2025-06-30T04:11:41.465177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_cat_cardinality_threshold = proj_configs.CATEGORICAL_CARDINALITY_THRESHOLD_ABS\n",
    "threshold_type = 'ABS'\n",
    "feature_categories = proj_utils_feat_engg.classify_columns(df=df_raw_train, n_cat_threshold=n_cat_cardinality_threshold, threshold_type=threshold_type, cols_to_ignore=ignorables_cols, temporal_cols_name_pattern=temporal_cols_name_pattern, ordinal_cols=ordinal_cols)"
   ],
   "id": "a7a54181e30f958",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T04:12:07.429278Z",
     "start_time": "2025-06-30T04:12:07.398239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cols_num_continuous, n_num_continuous, cols_num_discrete, n_num_discrete, cols_cat_nominal, n_cat_nominal, cols_cat_ordinal, n_cat_ordinal, cols_object, n_object, cols_temporal, n_temporal, cols_binary, n_binary = proj_utils_feat_engg.get_cols_as_tuple(feature_categories)\n",
    "\n",
    "n_total = df_raw_train.shape[1] - len(ignorables_cols)\n",
    "\n",
    "print(f'='*80)\n",
    "print(f'Total raw columns = {proj_utils_plots.beautify(len(df_raw_train.columns))} \\nNumerical Continuous = {proj_utils_plots.beautify(n_num_continuous)} \\nNumerical Discrete = {proj_utils_plots.beautify(n_num_discrete)} \\nCategorical Nominal = {proj_utils_plots.beautify(n_cat_nominal)} \\nCategorical Ordinal = {proj_utils_plots.beautify(n_cat_ordinal)} \\nObject/String = {proj_utils_plots.beautify(n_object)} \\nTemporal = {proj_utils_plots.beautify(n_temporal)} \\nBinary = {proj_utils_plots.beautify(n_binary)}')\n",
    "\n",
    "print(f'='*80)\n",
    "print(f'Any inconsistencies detected?[True/False] = {proj_utils_plots.beautify(\"True\", 3) if n_total != len(df_raw_train.columns) - len(ignorables_cols) else proj_utils_plots.beautify(\"False\", 1)}')\n",
    "print(f'='*80)"
   ],
   "id": "5f5c9dd9c6a705f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Total raw columns = \u001B[1m\u001B[35m82\u001B[0m \n",
      "Numerical Continuous = \u001B[1m\u001B[35m17\u001B[0m \n",
      "Numerical Discrete = \u001B[1m\u001B[35m14\u001B[0m \n",
      "Categorical Nominal = \u001B[1m\u001B[35m17\u001B[0m \n",
      "Categorical Ordinal = \u001B[1m\u001B[35m18\u001B[0m \n",
      "Object/String = \u001B[1m\u001B[35m7\u001B[0m \n",
      "Temporal = \u001B[1m\u001B[35m4\u001B[0m \n",
      "Binary = \u001B[1m\u001B[35m3\u001B[0m\n",
      "================================================================================\n",
      "Any inconsistencies detected?[True/False] = \u001B[1m\u001B[32mFalse\u001B[0m\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate the number of NaN values for each column\n",
    "nan_counts = df_raw.isna().sum()\n",
    "\n",
    "# Filter only columns that have NaN values and sort by the number of NaNs\n",
    "cols_with_nans = nan_counts[nan_counts > 0].index.tolist()\n",
    "print(f'Columns with NaNs: = {proj_utils_plots.beautify(len(cols_with_nans))}/{proj_utils_plots.beautify(n_total)}')\n",
    "print(f'And they are: {cols_with_nans}')"
   ],
   "id": "37ae4437ee9b5313",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_cardinality = proj_utils_feat_engg.get_cardinality_df(df_raw)",
   "id": "11e8333c6ef675a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_cardinality",
   "id": "53b28a112abc4332",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "proj_utils_plots.plot_cardinality(df_cardinality, n_cat_cardinality_threshold, threshold_used=threshold_type, type_of_cols='all', figsize=(20, 6))",
   "id": "804341bb4547354a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Zoom into cols having NaNs only\n",
    "proj_utils_plots.plot_cardinality(df_cardinality[df_cardinality['col_name'].isin(cols_with_nans)], n_cat_cardinality_threshold, threshold_used=threshold_type, type_of_cols=\"NaN\", figsize=(10, 6))"
   ],
   "id": "e2e3347129e57abc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_raw[cols_num_continuous].isnull().sum().sort_values(ascending=False)",
   "id": "5a29edbf7dd56d0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Creating a copy of the raw data to impute missing values for plotting purposes only (as NaNs are not plotted)\n",
    "df_imputed_for_plots = df_raw.copy()\n",
    "df_imputed_for_plots[cols_num_continuous] = df_imputed_for_plots[cols_num_continuous].fillna(0)\n",
    "most_frequent = df_imputed_for_plots[cols_num_discrete].mode().iloc[0]\n",
    "df_imputed_for_plots[cols_num_discrete] = df_imputed_for_plots[cols_num_discrete].fillna(most_frequent)"
   ],
   "id": "ef2ca147da0befc5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_imputed_for_plots",
   "id": "ec2adcd985825dc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_imputed_for_plots_v2 = df_raw[cols_num_continuous+['SalePrice']].copy()",
   "id": "b5bf19409fae99b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_imputed_for_plots_v2.sample(2)",
   "id": "891c743a604d4373",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# correlation_plot = plot_correlation_with_demand(df, save_path=\"correlation_plot.png\")\n",
    "correlation_plot = proj_utils_plots.plot_correlation_with_target(df_imputed_for_plots_v2, target_col)"
   ],
   "id": "6e372acf601b0ea0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "proj_utils_plots.plot_numerical_distribution(df_imputed_for_plots, cols_num_continuous)",
   "id": "6e705f9717f2acaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "proj_utils_plots.plot_categorical_distribution(df_imputed_for_plots, cols_cat_nominal)",
   "id": "b0482db21836bfd3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "proj_utils_plots.plot_categorical_distribution(df_imputed_for_plots, cols_cat_ordinal)",
   "id": "5cc64fc1e5fa526",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "proj_utils_plots.plot_relationship_to_target(df_imputed_for_plots, cols_num_discrete, target_col)",
   "id": "565be807881cf88d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "proj_utils_plots.plot_relationship_to_target(df_imputed_for_plots, cols_num_discrete, target_col, trend_type='median')",
   "id": "34e212dc79d02e14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df_raw.drop(ignorables_cols, axis=1),\n",
    "    df_raw[target_col],\n",
    "    test_size=proj_configs.VALIDATION_SIZE,\n",
    "    random_state=proj_configs.RANDOM_STATE\n",
    ")"
   ],
   "id": "57651d20d7b35ba7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train.shape, y_train.shape, X_val.shape, y_val.shape",
   "id": "40539573c8a9ad71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_columns = cols_num_continuous\n",
    "cat_columns = cols_cat_nominal + cols_cat_ordinal + cols_num_discrete + cols_binary + cols_object\n",
    "tempo_columns = cols_temporal"
   ],
   "id": "26440addd4e93771",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(num_columns), len(cat_columns), len(tempo_columns)",
   "id": "1847e20decebb02e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pproc_pipe = proj_utils_feat_engg.create_pproc_pipeline(num_columns, cat_columns, tempo_columns)",
   "id": "8bf6e9c951bd6c76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "mlflow.login()",
   "id": "179433c870506e32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# proj_utils_model.set_mlflow_uri('http://127.0.0.1:8080')\n",
    "proj_utils_model.set_mlflow_uri(\"databricks\")"
   ],
   "id": "19c88e6151c92703",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow_experiment_name = f\"/Users/asheesh.ambardar@live.com/{proj_configs.PROJECT_NAME}\"\n",
    "mlflow_experiment_id = proj_utils_model.get_or_create_experiment(mlflow_experiment_name)"
   ],
   "id": "b35f48c37d77d9a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "mlflow_experiment_id",
   "id": "aab859eeded8821f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "proj_utils_model.set_mlflow_experiment(mlflow_experiment_name)",
   "id": "49af076af4d9f832",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import warnings, logging\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "logging.getLogger(\"mlflow\").setLevel(logging.ERROR)"
   ],
   "id": "fc8e596f1be235",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train_transformed = pproc_pipe.fit_transform(X_train)",
   "id": "39926242db7dc827",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_val_transformed = pproc_pipe.transform(X_val)",
   "id": "75e65af0987fae80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_train_transformed = y_train.to_numpy()\n",
    "y_val_transformed = y_val.to_numpy()"
   ],
   "id": "d0d39608468e826f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check for both NaN and None\n",
    "has_nulls_or_nans = pd.isna(X_train_transformed).any()\n",
    "print(f\"Contains null or NaN values: {has_nulls_or_nans}\")"
   ],
   "id": "9169473752777ba1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "type(y_val)",
   "id": "7bf1cfaa4dd9cdc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "run_name='lasso-03'\n",
    "artefact_path = 'artefact_path'\n",
    "optimised_study_lasso = proj_utils_model.run_hyperparam_tuning_lasso(X_train, y_train, X_val, y_val, pproc_pipe, mlflow_experiment_id, run_name, artefact_path, proj_configs.OPTUNA_TRIAL_COUNT)"
   ],
   "id": "a11b7ce0f2cba7a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "run_name='xgb-02'\n",
    "artefact_path = 'artefact_path'\n",
    "optimised_study_xgb = proj_utils_model.run_hyperparam_tuning_xgb(X_train_transformed, y_train_transformed, X_val_transformed, y_val_transformed, mlflow_experiment_id, run_name, artefact_path, proj_configs.OPTUNA_TRIAL_COUNT)"
   ],
   "id": "e164911336104924",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b99716eff05af8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "run_name='rfc-05'\n",
    "artefact_path = 'artefact_path'\n",
    "optimised_study_rfc = proj_utils_model.run_hyperparam_tuning_rfc(X_train, y_train, X_val, y_val, pproc_pipe, mlflow_experiment_id, run_name, artefact_path, proj_configs.OPTUNA_TRIAL_COUNT)"
   ],
   "id": "58fd387356b54f49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "575da2c882629d2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_uri = mlflow.get_artifact_uri(artefact_path)\n",
    "model_uri"
   ],
   "id": "f9601a04226dce96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loaded_model = mlflow.sklearn.load_model(\n",
    "    model_uri=\"dbfs:/databricks/mlflow-tracking/1539464224853128/d72a53fe0a31467084ebeaceb1edc48e/artifacts/artefact_path\"\n",
    ")"
   ],
   "id": "2b1ef5dd7c0def75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "loaded_model",
   "id": "c2dfeac181ec5d64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_raw_test = proj_utils_data_loader.load_data(proj_configs.TEST_FILE)",
   "id": "f9813d5c1c2f894f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_test = proj_utils_data_loader.refactor_col_names(df_raw_test)",
   "id": "def8103b96c87508",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_test.sample(3)",
   "id": "a8565fbd09eb96f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_test.drop(insignificant_cols, axis=1, inplace=True)",
   "id": "f1c98123876eafa2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_test_transformed = pproc_pipe.transform(df_test)\n",
    "type(data_test_transformed)"
   ],
   "id": "238e2c79243696a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check for both NaN and None\n",
    "has_nulls_or_nans = pd.isna(df_test_transformed).any()\n",
    "print(f\"Contains null or NaN values: {has_nulls_or_nans}\")"
   ],
   "id": "3ee508e6c4787cd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_raw_train = df_raw.copy()\n",
    "df_raw_train.drop(ignorables_cols, axis=1, inplace=True)"
   ],
   "id": "9ed7501cd4edf825",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_train_transformed = pproc_pipe.transform(df_raw_train)\n",
    "type(data_train_transformed)"
   ],
   "id": "7f592343c68b691f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check for both NaN and None\n",
    "has_nulls_or_nans = pd.isna(df_train_transformed).any()\n",
    "print(f\"Contains null or NaN values: {has_nulls_or_nans}\")"
   ],
   "id": "af40d43c07e572d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_target = df_raw[target_col].to_numpy()\n",
    "type(data_target)"
   ],
   "id": "1ec822cb82024ada",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "loaded_model.fit(data_train_transformed, data_target)",
   "id": "be9247fae05618e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_preds = loaded_model.predict(data_train_transformed)\n",
    "train_actuals = data_target"
   ],
   "id": "8e369c283caeff2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate the model\n",
    "train_mse = mean_squared_error(train_actuals, train_preds).round(5)\n",
    "train_r2 = r2_score(train_actuals, train_preds).round(5)\n",
    "\n",
    "print(\"=== Model Performance ===\")\n",
    "print(f\"Train MSE: {proj_utils_plots.beautify(train_mse)}, Train R2: {proj_utils_plots.beautify(train_r2)}\")"
   ],
   "id": "b8c7ae9eaa5ce6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_preds = loaded_model.predict(data_test_transformed)",
   "id": "3b9b0432f7f6176b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_preds",
   "id": "359858a87b51c212",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "my_submission = pd.DataFrame({'Id': df_raw_test.Id, 'SalePrice': test_preds})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('submission.csv', index=False)"
   ],
   "id": "ace23632daf3e027",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "19b99d11f56ec07f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "31dd1df29e5ced5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "482be93cb73a5911",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# this is a Trial object, not the underlying ML object.\n",
    "best_performing_trial = optimised_study_xgb.best_trial\n",
    "print(f'Best trial was at number {proj_utils_plots.beautify(str(best_performing_trial.number), 1)} with params as:\\n {proj_utils_plots.beautify(str(best_performing_trial.params), 2)}')\n",
    "print(f'Best score value is: {proj_utils_plots.beautify(str(best_performing_trial.value))}')"
   ],
   "id": "4a77b77c006c759a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_performing_trial",
   "id": "31d846d4b65b7a22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "study_full_metrics = optimised_study_xgb.trials_dataframe()\n",
    "# save the metrics to a file\n",
    "proj_utils_model.save_hyperparams(f'full_metrics_{proj_utils.get_current_timestamp()}.csv', proj_configs.PATH_OUT_MODELS, study_full_metrics)\n",
    "\n",
    "# peek at the full metrics dataframe\n",
    "study_full_metrics"
   ],
   "id": "657b2c2f510cd79a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# fetch number of trial runs per model type\n",
    "num_lr_trials = study_full_metrics[study_full_metrics['params_model'] == 'lr'].shape[0]\n",
    "num_lasso_trials = study_full_metrics[study_full_metrics['params_model'] == 'lasso'].shape[0]\n",
    "num_ridge_trials = study_full_metrics[study_full_metrics['params_model'] == 'ridge'].shape[0]\n",
    "num_elasticnet_trials = study_full_metrics[study_full_metrics['params_model'] == 'elasticnet'].shape[0]\n",
    "\n",
    "print(f'Total trials = {proj_utils_plots.beautify(str(num_lr_trials + num_lasso_trials + num_ridge_trials + num_elasticnet_trials), 1)}\\n-- LR trials = {proj_utils_plots.beautify(str(num_lr_trials), 1)}\\n-- Lasso trials = {proj_utils_plots.beautify(str(num_lasso_trials), 1)}\\n-- Ridge trials = {proj_utils_plots.beautify(str(num_ridge_trials), 1)}\\n-- ElasticNet trials = {proj_utils_plots.beautify(str(num_elasticnet_trials), 1)}')"
   ],
   "id": "2c629463bc37a59b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# retrieve all performance values for each model type studied\n",
    "grp_by_model_type_val = study_full_metrics.groupby('params_model')['value'].apply(list)\n",
    "# retrieve the best performing model (use nsmallest if Optuna objective was to minimise,\n",
    "grp_by_model_type_best_val = study_full_metrics.groupby('params_model')['value'].nsmallest(1)\n",
    "# display the stats\n",
    "grp_by_model_type_best_val"
   ],
   "id": "455d563c4610f4d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    " # grouping Optuna metrics by model type and using idxmax (or idmin) method to find a row with the best model performance (value) for each group\n",
    "study_best_model_group = study_full_metrics.loc[study_full_metrics.groupby('params_model')['value'].idxmin()]"
   ],
   "id": "30208428b7d90d20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "study_best_model_group",
   "id": "d2f168858eabbdf2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# retrieve the trial number of the best model for each model type - the Optuna metrics dataframe index and trial number are the same.\n",
    "best_lr_trial = study_best_model_group[study_best_model_group['params_model'] == 'lr']['number'].values[0]\n",
    "best_lasso_trial = study_best_model_group[study_best_model_group['params_model'] == 'lasso']['number'].values[0]\n",
    "best_ridge_trial = study_best_model_group[study_best_model_group['params_model'] == 'ridge']['number'].values[0]\n",
    "best_elasticnet_trial = study_best_model_group[study_best_model_group['params_model'] == 'elasticnet']['number'].values[0]\n",
    "\n",
    "final_pipe_best_lr = models[best_lr_trial]\n",
    "best_model_lr = final_pipe_best_lr.named_steps['regressor']\n",
    "final_pipe_best_lasso = models[best_lasso_trial]\n",
    "best_model_lasso = final_pipe_best_lasso.named_steps['regressor']\n",
    "final_pipe_best_ridge = models[best_ridge_trial]\n",
    "best_model_ridge = final_pipe_best_ridge.named_steps['regressor']\n",
    "final_pipe_best_elasticnet = models[best_elasticnet_trial]\n",
    "best_model_elasticnet = final_pipe_best_elasticnet.named_steps['regressor']\n",
    "\n",
    "# retrieve the best model object (amongst all model types evaluated)\n",
    "final_pipe_best = models[best_performing_trial.number]\n",
    "best_model = final_pipe_best.named_steps['regressor']"
   ],
   "id": "6233d4364e331135",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_pipe_best",
   "id": "f7a2a5cb76f9512d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_pipe_best.fit(X_train, y_train)",
   "id": "a7fc4a11b6e8b14e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cols_final_inputs, cols_final_output_features = proj_utils_feat_engg.get_final_features(final_pipe_best, X_train)",
   "id": "38d1696dc80f1fdb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "proj_utils_model.save_features(f'pproc_final_input_cols_{len(cols_final_inputs)}_{proj_utils.get_current_timestamp()}.csv', proj_configs.PATH_OUT_FEATURES, pd.DataFrame(cols_final_inputs))\n",
    "proj_utils_model.save_features(f'pproc_final_output_features_{len(cols_final_output_features)}_{proj_utils.get_current_timestamp()}.csv', proj_configs.PATH_OUT_FEATURES, pd.DataFrame(cols_final_output_features))"
   ],
   "id": "a22159b4cc78d7af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "proj_utils_model.save_model(f'final_pipe_{proj_utils.get_current_timestamp()}.pkl', proj_configs.PATH_OUT_MODELS, final_pipe_best)",
   "id": "65b972ae40e6a624",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_train_preds = final_pipe_best.predict(X_train)\n",
    "y_val_preds = final_pipe_best.predict(X_val)"
   ],
   "id": "bff38c8eaa4fe415",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate the model\n",
    "train_mse = mean_squared_error(y_train, y_train_preds).round(5)\n",
    "val_mse = mean_squared_error(y_val, y_val_preds).round(5)\n",
    "train_r2 = r2_score(y_train, y_train_preds).round(5)\n",
    "val_r2 = r2_score(y_val, y_val_preds).round(5)\n",
    "\n",
    "print(\"=== Model Performance ===\")\n",
    "print(f\"Train MSE: {proj_utils_plots.beautify(train_mse)}, Train R2: {proj_utils_plots.beautify(train_r2)}\")\n",
    "print(f\"Validation MSE: {proj_utils_plots.beautify(val_mse)}, Validation R2: {proj_utils_plots.beautify(val_r2)}\")"
   ],
   "id": "36fce385b777a442",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "string_to_log = f'=== Model Performance === \\n Train MSE: {train_mse}, Train R2: {train_r2} \\n Validation MSE: {val_mse}, Validation R2: {val_r2}'\n",
    "proj_utils.save_file('metrics', 'validation_metrics.txt', proj_configs.PATH_OUT_MODELS, string_to_log)"
   ],
   "id": "bcc70e6544b2a605",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d05ca7a227112434",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
