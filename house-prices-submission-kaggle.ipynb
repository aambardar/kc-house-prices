{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Academic Integrity and Learning Statement\n",
    "\n",
    "By submitting my work, I confirm that:\n",
    "\n",
    "1. The code, analysis, and documentation in this notebook are my own work and reflect my own understanding.\n",
    "2. I am prepared to explain all code and analysis included in this submission.\n",
    "\n",
    "If I used assistance (e.g., AI tools, tutors, or other resources), I have:\n",
    "\n",
    "- Clearly documented where and how external tools or resources were used in my solution.\n",
    "- Included a copy of the interaction (e.g., AI conversation or tutoring notes) in an appendix.\n",
    "\n",
    "I acknowledge that:\n",
    "\n",
    "- I may be asked to explain any part of my code or analysis during evaluation.\n",
    "- Misrepresenting assisted work as my own constitutes academic dishonesty and undermines my learning."
   ],
   "id": "71e8cdf0751690d6"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-14T00:41:23.470889Z",
     "start_time": "2025-07-14T00:41:12.679385Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import subprocess\n",
    "\n",
    "import comet_ml, mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import optuna\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import platform\n",
    "from joblib import load"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T00:41:28.465216Z",
     "start_time": "2025-07-14T00:41:28.424328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Enable auto-reload extension\n",
    "%load_ext autoreload\n",
    "# Automatically reload all modules before executing code\n",
    "%autoreload 2"
   ],
   "id": "c46da9c6fd73de53",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T00:41:29.757610Z",
     "start_time": "2025-07-14T00:41:29.224308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import base_utils_logging\n",
    "import proj_utils_data_loader\n",
    "import proj_configs\n",
    "import proj_utils\n",
    "import proj_utils_feat_engg\n",
    "import proj_utils_plots\n",
    "import proj_utils_model"
   ],
   "id": "88ba6ac1d373ffce",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T00:41:30.123965Z",
     "start_time": "2025-07-14T00:41:30.095606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")"
   ],
   "id": "f5129035565a3994",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T00:41:31.769080Z",
     "start_time": "2025-07-14T00:41:31.709300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check software specs\n",
    "dict_sw_version = {\n",
    "    'python': os.popen('python --version').read().strip(),\n",
    "    'numpy': np.__version__,\n",
    "    'pandas': pd.__version__,\n",
    "    'optuna': optuna.__version__,\n",
    "    'mlflow': mlflow.__version__,\n",
    "}\n",
    "\n",
    "for key, value in dict_sw_version.items():\n",
    "    print(f'{proj_utils_plots.beautify(key, 1)} version is: {proj_utils_plots.beautify(value)}')\n"
   ],
   "id": "6d24b286ccfc7d22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m\u001B[32mpython\u001B[0m version is: \u001B[1m\u001B[35mPython 3.11.13\u001B[0m\n",
      "\u001B[1m\u001B[32mnumpy\u001B[0m version is: \u001B[1m\u001B[35m1.26.4\u001B[0m\n",
      "\u001B[1m\u001B[32mpandas\u001B[0m version is: \u001B[1m\u001B[35m2.2.3\u001B[0m\n",
      "\u001B[1m\u001B[32moptuna\u001B[0m version is: \u001B[1m\u001B[35m4.4.0\u001B[0m\n",
      "\u001B[1m\u001B[32mmlflow\u001B[0m version is: \u001B[1m\u001B[35m2.18.0\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T00:41:36.105328Z",
     "start_time": "2025-07-14T00:41:35.750626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check hardware specs\n",
    "def get_mac_gpu_info():\n",
    "    try:\n",
    "        # Get system information about GPU\n",
    "        result = subprocess.run(['system_profiler', 'SPDisplaysDataType'],\n",
    "                              capture_output=True, text=True)\n",
    "        return result.stdout\n",
    "    except Exception as e:\n",
    "        return f\"Error getting GPU info: {e}\"\n",
    "\n",
    "# Check CPU cores\n",
    "print(f'CPU cores available to use: {proj_utils_plots.beautify(str(multiprocessing.cpu_count()))}')\n",
    "\n",
    "# Check MPS availability\n",
    "print(\"TensorFlow GPU devices:\", proj_utils_plots.beautify(tf.config.list_physical_devices('GPU')))\n",
    "print(f\"Processor: {proj_utils_plots.beautify(platform.processor())}\")\n",
    "print(f\"Machine: {proj_utils_plots.beautify(platform.machine())}\")\n",
    "\n",
    "print(\"PyTorch MPS (Metal) Status:\")\n",
    "print(f\"MPS available: {proj_utils_plots.beautify(torch.backends.mps.is_available())}\")\n",
    "print(f\"MPS built: {proj_utils_plots.beautify(str(torch.backends.mps.is_built()))}\")\n",
    "\n",
    "# Get detailed GPU information\n",
    "print(\"\\nDetailed GPU Information:\")\n",
    "print(get_mac_gpu_info())"
   ],
   "id": "337330b589c6a835",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU cores available to use: \u001B[1m\u001B[35m10\u001B[0m\n",
      "TensorFlow GPU devices: \u001B[1m\u001B[35m[]\u001B[0m\n",
      "Processor: \u001B[1m\u001B[35marm\u001B[0m\n",
      "Machine: \u001B[1m\u001B[35marm64\u001B[0m\n",
      "PyTorch MPS (Metal) Status:\n",
      "MPS available: \u001B[1m\u001B[35mTrue\u001B[0m\n",
      "MPS built: \u001B[1m\u001B[35mTrue\u001B[0m\n",
      "\n",
      "Detailed GPU Information:\n",
      "Graphics/Displays:\n",
      "\n",
      "    Apple M4:\n",
      "\n",
      "      Chipset Model: Apple M4\n",
      "      Type: GPU\n",
      "      Bus: Built-In\n",
      "      Total Number of Cores: 10\n",
      "      Vendor: Apple (0x106b)\n",
      "      Metal Support: Metal 3\n",
      "      Displays:\n",
      "        DELL U3425WE:\n",
      "          Resolution: 3440 x 1440 (UWQHD - Ultra-Wide Quad HD)\n",
      "          UI Looks like: 3440 x 1440 @ 100.00Hz\n",
      "          Main Display: Yes\n",
      "          Mirror: Off\n",
      "          Online: Yes\n",
      "          Rotation: Supported\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T00:41:37.555792Z",
     "start_time": "2025-07-14T00:41:37.513814Z"
    }
   },
   "cell_type": "code",
   "source": "base_utils_logging.setup_logging()",
   "id": "a31b0f710678697c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T00:41:38.185257Z",
     "start_time": "2025-07-14T00:41:38.130554Z"
    }
   },
   "cell_type": "code",
   "source": "base_utils_logging.logger.info('Starting the application')",
   "id": "4e9d276c1b24d439",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T00:41:40.052824Z",
     "start_time": "2025-07-14T00:41:39.958479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_raw_train = proj_utils_data_loader.load_data(proj_configs.TRAIN_FILE)\n",
    "df_raw_test = proj_utils_data_loader.load_data(proj_configs.TEST_FILE)\n",
    "df_raw_train.shape, df_raw_test.shape"
   ],
   "id": "eed9d9da9617bed0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 81), (1459, 80))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T00:41:41.355171Z",
     "start_time": "2025-07-14T00:41:41.307571Z"
    }
   },
   "cell_type": "code",
   "source": "df_raw_train.sample(3)",
   "id": "d3f3a25cad6101e2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "826  827          45       RM         50.0     6130   Pave   NaN      Reg   \n",
       "528  529          30       RL         58.0     9098   Pave   NaN      IR1   \n",
       "557  558          50  C (all)         60.0    11040   Pave   NaN      Reg   \n",
       "\n",
       "    LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "826         Lvl    AllPub  ...        0    NaN   NaN         NaN       0   \n",
       "528         Lvl    AllPub  ...        0    NaN   NaN         NaN       0   \n",
       "557         Low    AllPub  ...        0    NaN   NaN         NaN       0   \n",
       "\n",
       "    MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "826      5   2008        WD         Normal     109500  \n",
       "528      7   2007        WD         Normal      86000  \n",
       "557      9   2006       COD         Normal     108000  \n",
       "\n",
       "[3 rows x 81 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>827</td>\n",
       "      <td>45</td>\n",
       "      <td>RM</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6130</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>109500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>529</td>\n",
       "      <td>30</td>\n",
       "      <td>RL</td>\n",
       "      <td>58.0</td>\n",
       "      <td>9098</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>86000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>558</td>\n",
       "      <td>50</td>\n",
       "      <td>C (all)</td>\n",
       "      <td>60.0</td>\n",
       "      <td>11040</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Low</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2006</td>\n",
       "      <td>COD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 81 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T00:42:07.592022Z",
     "start_time": "2025-07-14T00:42:07.560521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "low_cardinality_cols = [cname for cname in df_raw_train.columns\n",
    "                        if df_raw_train[cname].nunique() < 10 and\n",
    "                        df_raw_train[cname].dtype == \"object\"]"
   ],
   "id": "3e6c2fbde4e4428",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T00:42:24.455531Z",
     "start_time": "2025-07-14T00:42:24.423207Z"
    }
   },
   "cell_type": "code",
   "source": "len(low_cardinality_cols)",
   "id": "2b4a1f3e9596a515",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T00:44:31.590323Z",
     "start_time": "2025-07-14T00:44:31.551263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO: uncomment and comment below insignificant col list\n",
    "# insignificant_cols = ['Order', 'PID']\n",
    "insignificant_cols = ['Id']\n",
    "target_col = 'SalePrice'\n",
    "ignorables_cols = insignificant_cols + [target_col]\n",
    "ordinal_cols = ['LotShape', 'Utilities', 'LandSlope', 'OverallQual', 'OverallCond', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']\n",
    "temporal_cols_name_pattern = ['Yr', 'Year']"
   ],
   "id": "6edf5a9a26a9e843",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T00:44:32.397668Z",
     "start_time": "2025-07-14T00:44:32.324867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_raw_all, df_raw_target = proj_utils_data_loader.merge_train_test_data(df_raw_train, df_raw_test, insignificant_cols, target_col)\n",
    "df_raw_all.shape, df_raw_target.shape"
   ],
   "id": "654f96a21abe775e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2919, 80), (1460,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T00:44:33.040193Z",
     "start_time": "2025-07-14T00:44:33.005839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Slice of train data records from the merged data frame\n",
    "df_train = df_raw_all[df_raw_all['is_train']==1].iloc[:,:-1]\n",
    "df_test = df_raw_all[df_raw_all['is_train']==0].iloc[:, :-1]"
   ],
   "id": "e2bde6206601a714",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T00:44:34.146045Z",
     "start_time": "2025-07-14T00:44:34.141824Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "23d92e996dde6775",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T00:44:34.682700Z",
     "start_time": "2025-07-14T00:44:34.555192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_cat_cardinality_threshold = proj_configs.CATEGORICAL_CARDINALITY_THRESHOLD_ABS\n",
    "threshold_type = 'ABS'\n",
    "feature_categories = proj_utils_feat_engg.classify_columns(df=df_train, n_cat_threshold=n_cat_cardinality_threshold, threshold_type=threshold_type, cols_to_ignore=ignorables_cols, temporal_cols_name_pattern=temporal_cols_name_pattern, ordinal_cols=ordinal_cols)"
   ],
   "id": "a7a54181e30f958",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T00:44:35.289050Z",
     "start_time": "2025-07-14T00:44:35.238045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cols_num_continuous, n_num_continuous, cols_num_discrete, n_num_discrete, cols_cat_nominal, n_cat_nominal, cols_cat_ordinal, n_cat_ordinal, cols_object, n_object, cols_temporal, n_temporal, cols_binary, n_binary = proj_utils_feat_engg.get_cols_as_tuple(feature_categories)\n",
    "\n",
    "n_total = df_train.shape[1] - len(ignorables_cols)\n",
    "\n",
    "print(f\"=\"*80)\n",
    "print(f\"Total raw columns = {proj_utils_plots.beautify(str(len(df_train.columns)))} \\nNumerical Continuous = {proj_utils_plots.beautify(n_num_continuous)} \\nNumerical Discrete = {proj_utils_plots.beautify(n_num_discrete)} \\nCategorical Nominal = {proj_utils_plots.beautify(n_cat_nominal)} \\nCategorical Ordinal = {proj_utils_plots.beautify(n_cat_ordinal)} \\nObject/String = {proj_utils_plots.beautify(n_object)} \\nTemporal = {proj_utils_plots.beautify(n_temporal)} \\nBinary = {proj_utils_plots.beautify(n_binary)}\")\n",
    "\n",
    "print(f\"=\"*80)\n",
    "print(f\"Any inconsistencies detected?[True/False] = {proj_utils_plots.beautify('True', 3) if n_total != len(df_train.columns) - len(ignorables_cols) else proj_utils_plots.beautify('False', 1)}\")\n",
    "print(f'='*80)"
   ],
   "id": "5f5c9dd9c6a705f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Total raw columns = \u001B[1m\u001B[35m79\u001B[0m \n",
      "Numerical Continuous = \u001B[1m\u001B[35m20\u001B[0m \n",
      "Numerical Discrete = \u001B[1m\u001B[35m10\u001B[0m \n",
      "Categorical Nominal = \u001B[1m\u001B[35m17\u001B[0m \n",
      "Categorical Ordinal = \u001B[1m\u001B[35m18\u001B[0m \n",
      "Object/String = \u001B[1m\u001B[35m7\u001B[0m \n",
      "Temporal = \u001B[1m\u001B[35m4\u001B[0m \n",
      "Binary = \u001B[1m\u001B[35m3\u001B[0m\n",
      "================================================================================\n",
      "Any inconsistencies detected?[True/False] = \u001B[1m\u001B[32mFalse\u001B[0m\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate the number of NaN values for each column\n",
    "nan_counts = df_train.isna().sum()\n",
    "\n",
    "# Filter only columns that have NaN values and sort by the number of NaNs\n",
    "cols_with_nans = nan_counts[nan_counts > 0].index.tolist()\n",
    "print(f\"Columns with NaNs: = {proj_utils_plots.beautify(str(len(cols_with_nans)))}/{proj_utils_plots.beautify(n_total)}\")\n",
    "print(f\"And they are: {cols_with_nans}\")"
   ],
   "id": "37ae4437ee9b5313",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_cardinality = proj_utils_feat_engg.get_cardinality_df(df_train)",
   "id": "11e8333c6ef675a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_cardinality",
   "id": "53b28a112abc4332",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "proj_utils_plots.plot_cardinality(df_cardinality, n_cat_cardinality_threshold, threshold_used=threshold_type, type_of_cols='all', figsize=(20, 6))",
   "id": "804341bb4547354a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Zoom into cols having NaNs only\n",
    "proj_utils_plots.plot_cardinality(df_cardinality[df_cardinality['col_name'].isin(cols_with_nans)], n_cat_cardinality_threshold, threshold_used=threshold_type, type_of_cols=\"NaN\", figsize=(10, 6))"
   ],
   "id": "e2e3347129e57abc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_train[cols_num_continuous].isnull().sum().sort_values(ascending=False)",
   "id": "5a29edbf7dd56d0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Creating a copy of the raw data to impute missing values for plotting purposes only (as NaNs are not plotted)\n",
    "df_imputed_for_plots = df_train.copy()\n",
    "df_imputed_for_plots[cols_num_continuous] = df_imputed_for_plots[cols_num_continuous].fillna(0)\n",
    "most_frequent = df_imputed_for_plots[cols_num_discrete].mode().iloc[0]\n",
    "df_imputed_for_plots[cols_num_discrete] = df_imputed_for_plots[cols_num_discrete].fillna(most_frequent)"
   ],
   "id": "ef2ca147da0befc5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_imputed_for_plots",
   "id": "ec2adcd985825dc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_raw_target",
   "id": "b1aa4286799fc93c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_imputed_for_plots_v2 = pd.concat([df_train[cols_num_continuous], df_raw_target], axis=1)",
   "id": "b5bf19409fae99b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_imputed_for_plots_v2.sample(2)",
   "id": "891c743a604d4373",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# correlation_plot = plot_correlation_with_demand(df, save_path=\"correlation_plot.png\")\n",
    "correlation_plot = proj_utils_plots.plot_correlation_with_target(df_imputed_for_plots_v2, target_col)"
   ],
   "id": "6e372acf601b0ea0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "proj_utils_plots.plot_numerical_distribution(df_imputed_for_plots, cols_num_continuous)",
   "id": "6e705f9717f2acaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "proj_utils_plots.plot_categorical_distribution(df_imputed_for_plots, cols_cat_nominal)",
   "id": "b0482db21836bfd3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "proj_utils_plots.plot_categorical_distribution(df_imputed_for_plots, cols_cat_ordinal)",
   "id": "5cc64fc1e5fa526",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "proj_utils_plots.plot_relationship_to_target(df_imputed_for_plots, cols_num_discrete, target_col)",
   "id": "565be807881cf88d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "proj_utils_plots.plot_relationship_to_target(df_imputed_for_plots, cols_num_discrete, target_col, trend_type='median')",
   "id": "34e212dc79d02e14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df_train,\n",
    "    df_raw_target,\n",
    "    test_size=proj_configs.VALIDATION_SIZE,\n",
    "    random_state=proj_configs.RANDOM_STATE\n",
    ")"
   ],
   "id": "57651d20d7b35ba7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train.shape, y_train.shape, X_val.shape, y_val.shape",
   "id": "40539573c8a9ad71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_columns = cols_num_continuous\n",
    "cat_columns = cols_cat_nominal + cols_cat_ordinal + cols_num_discrete + cols_binary + cols_object\n",
    "tempo_columns = cols_temporal"
   ],
   "id": "26440addd4e93771",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(num_columns), len(cat_columns), len(tempo_columns)",
   "id": "1847e20decebb02e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pproc_pipe = proj_utils_feat_engg.create_pproc_pipeline(num_columns, cat_columns, tempo_columns)",
   "id": "8bf6e9c951bd6c76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "daa38382de0ade53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Login to mlflow\n",
    "# mlflow.login()\n",
    "# proj_utils_model.set_mlflow_uri(\"databricks\")\n",
    "# mlflow_experiment_name = f\"/Users/asheesh.ambardar@live.com/{proj_configs.PROJECT_NAME}\"\n",
    "# mlflow_experiment_id = proj_utils_model.get_or_create_experiment(mlflow_experiment_name)\n",
    "# proj_utils_model.set_mlflow_experiment(mlflow_experiment_name)\n",
    "# model_uri = mlflow.get_artifact_uri(artefact_path)\n",
    "# model_uri"
   ],
   "id": "179433c870506e32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "comet_experiment = comet_ml.Experiment()\n",
    "# comet_experiment.set_name(proj_configs.PROJECT_NAME)"
   ],
   "id": "fe076592ea14ce7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Verify connection\n",
    "if comet_experiment.api_key:\n",
    "    print(\"Successfully connected to Comet ML!\")\n",
    "else:\n",
    "    print(\"Failed to connect to Comet ML\")\n"
   ],
   "id": "f8cdb11560d30c5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "82f483bc1028840a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "19c88e6151c92703",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b35f48c37d77d9a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "aab859eeded8821f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "49af076af4d9f832",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import warnings, logging\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "logging.getLogger(\"mlflow\").setLevel(logging.ERROR)"
   ],
   "id": "fc8e596f1be235",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train_transformed = pproc_pipe.fit_transform(X_train)",
   "id": "39926242db7dc827",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_val_transformed = pproc_pipe.transform(X_val)",
   "id": "75e65af0987fae80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_train_transformed = y_train.to_numpy()\n",
    "y_val_transformed = y_val.to_numpy()"
   ],
   "id": "d0d39608468e826f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check for both NaN and None\n",
    "has_nulls_or_nans = pd.isna(X_train_transformed).any()\n",
    "print(f\"Contains null or NaN values: {has_nulls_or_nans}\")"
   ],
   "id": "9169473752777ba1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "type(y_val)",
   "id": "7bf1cfaa4dd9cdc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "comet_experiment = comet_ml.Experiment()\n",
    "run_name='xgb-10'\n",
    "try:\n",
    "    optimised_study_xgb = proj_utils_model.run_hyperparam_tuning_xgb_exp(X_train_transformed, y_train_transformed, X_val_transformed, y_val_transformed, comet_experiment, run_name, proj_configs.OPTUNA_TRIAL_COUNT)\n",
    "finally:\n",
    "    comet_experiment.end()"
   ],
   "id": "7ccb415827288759",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e87c532874678e14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "107c89f0b327c6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "58fd387356b54f49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "def safe_load_model(model_path):\n",
    "        try:\n",
    "            if not os.path.exists(model_path):\n",
    "                raise FileNotFoundError(f\"Model file not found at {model_path}\")\n",
    "\n",
    "            with open(model_path, 'rb') as f:\n",
    "                model = pickle.load(f)\n",
    "            return model\n",
    "        except (pickle.UnpicklingError, KeyError) as e:\n",
    "            print(f\"Error loading model: {str(e)}\")\n",
    "            print(\"This might be due to version mismatch or corrupted file\")\n",
    "            return None\n",
    "\n",
    "# Load the model\n",
    "model_path = f\"{proj_configs.PATH_OUT_MODELS}xgb_model.pkl\"\n",
    "loaded_model = safe_load_model(model_path)\n",
    "\n",
    "if loaded_model is not None:\n",
    "    print(\"Model loaded successfully\")"
   ],
   "id": "d50a7addf30bb5f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "loaded_model",
   "id": "e4cb153a38d097af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_test = df_raw_all[df_raw_all['is_train']==0].iloc[:,:-1]",
   "id": "def8103b96c87508",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_test.sample(3)",
   "id": "a8565fbd09eb96f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_test_transformed = pproc_pipe.transform(df_test)\n",
    "type(data_test_transformed)"
   ],
   "id": "238e2c79243696a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check for both NaN and None\n",
    "has_nulls_or_nans = pd.isna(data_test_transformed).any()\n",
    "print(f\"Contains null or NaN values: {has_nulls_or_nans}\")"
   ],
   "id": "3ee508e6c4787cd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_train_transformed = pproc_pipe.transform(df_train)\n",
    "type(data_train_transformed)"
   ],
   "id": "f248860b1ad02e1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check for both NaN and None\n",
    "has_nulls_or_nans = pd.isna(data_train_transformed).any()\n",
    "print(f\"Contains null or NaN values: {has_nulls_or_nans}\")"
   ],
   "id": "1ec822cb82024ada",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_raw_target.shape",
   "id": "3b881d6ceea929c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_target = df_raw_target.to_numpy()",
   "id": "e21329d4d2c6ecd0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "loaded_model.fit(data_train_transformed, data_target)",
   "id": "be9247fae05618e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_preds = loaded_model.predict(data_train_transformed)\n",
    "train_actuals = data_target"
   ],
   "id": "8e369c283caeff2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "type(train_preds)",
   "id": "688bc632cc5fea1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate the model\n",
    "train_mse = round(mean_squared_error(train_actuals, train_preds), 5)\n",
    "train_r2 = round(r2_score(train_actuals, train_preds), 5)\n",
    "\n",
    "print(\"=== Model Performance ===\")\n",
    "print(f\"Train MSE: {proj_utils_plots.beautify(train_mse)}, Train R2: {proj_utils_plots.beautify(train_r2)}\")"
   ],
   "id": "b8c7ae9eaa5ce6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_preds = loaded_model.predict(data_test_transformed)",
   "id": "3b9b0432f7f6176b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_preds",
   "id": "359858a87b51c212",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_my_submission = pd.DataFrame({'Id': df_raw_test.Id, 'SalePrice': test_preds})\n",
    "my_submission_file = f\"{proj_configs.PATH_OUT_SUBMISSIONS}submission.csv\"\n",
    "df_my_submission.to_csv(my_submission_file, index=False)"
   ],
   "id": "ace23632daf3e027",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "19b99d11f56ec07f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "31dd1df29e5ced5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "482be93cb73a5911",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# this is a Trial object, not the underlying ML object.\n",
    "best_performing_trial = optimised_study_xgb.best_trial\n",
    "print(f'Best trial was at number {proj_utils_plots.beautify(str(best_performing_trial.number), 1)} with params as:\\n {proj_utils_plots.beautify(str(best_performing_trial.params), 2)}')\n",
    "print(f'Best score value is: {proj_utils_plots.beautify(str(best_performing_trial.value))}')"
   ],
   "id": "4a77b77c006c759a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_performing_trial",
   "id": "31d846d4b65b7a22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "study_full_metrics = optimised_study_xgb.trials_dataframe()\n",
    "# save the metrics to a file\n",
    "proj_utils_model.save_hyperparams(f'full_metrics_{proj_utils.get_current_timestamp()}.csv', proj_configs.PATH_OUT_MODELS, study_full_metrics)\n",
    "\n",
    "# peek at the full metrics dataframe\n",
    "study_full_metrics"
   ],
   "id": "657b2c2f510cd79a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# fetch number of trial runs per model type\n",
    "num_lr_trials = study_full_metrics[study_full_metrics['params_model'] == 'lr'].shape[0]\n",
    "num_lasso_trials = study_full_metrics[study_full_metrics['params_model'] == 'lasso'].shape[0]\n",
    "num_ridge_trials = study_full_metrics[study_full_metrics['params_model'] == 'ridge'].shape[0]\n",
    "num_elasticnet_trials = study_full_metrics[study_full_metrics['params_model'] == 'elasticnet'].shape[0]\n",
    "\n",
    "print(f'Total trials = {proj_utils_plots.beautify(str(num_lr_trials + num_lasso_trials + num_ridge_trials + num_elasticnet_trials), 1)}\\n-- LR trials = {proj_utils_plots.beautify(str(num_lr_trials), 1)}\\n-- Lasso trials = {proj_utils_plots.beautify(str(num_lasso_trials), 1)}\\n-- Ridge trials = {proj_utils_plots.beautify(str(num_ridge_trials), 1)}\\n-- ElasticNet trials = {proj_utils_plots.beautify(str(num_elasticnet_trials), 1)}')"
   ],
   "id": "2c629463bc37a59b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# retrieve all performance values for each model type studied\n",
    "grp_by_model_type_val = study_full_metrics.groupby('params_model')['value'].apply(list)\n",
    "# retrieve the best performing model (use nsmallest if Optuna objective was to minimise,\n",
    "grp_by_model_type_best_val = study_full_metrics.groupby('params_model')['value'].nsmallest(1)\n",
    "# display the stats\n",
    "grp_by_model_type_best_val"
   ],
   "id": "455d563c4610f4d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    " # grouping Optuna metrics by model type and using idxmax (or idmin) method to find a row with the best model performance (value) for each group\n",
    "study_best_model_group = study_full_metrics.loc[study_full_metrics.groupby('params_model')['value'].idxmin()]"
   ],
   "id": "30208428b7d90d20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "study_best_model_group",
   "id": "d2f168858eabbdf2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# retrieve the trial number of the best model for each model type - the Optuna metrics dataframe index and trial number are the same.\n",
    "best_lr_trial = study_best_model_group[study_best_model_group['params_model'] == 'lr']['number'].values[0]\n",
    "best_lasso_trial = study_best_model_group[study_best_model_group['params_model'] == 'lasso']['number'].values[0]\n",
    "best_ridge_trial = study_best_model_group[study_best_model_group['params_model'] == 'ridge']['number'].values[0]\n",
    "best_elasticnet_trial = study_best_model_group[study_best_model_group['params_model'] == 'elasticnet']['number'].values[0]\n",
    "\n",
    "final_pipe_best_lr = models[best_lr_trial]\n",
    "best_model_lr = final_pipe_best_lr.named_steps['regressor']\n",
    "final_pipe_best_lasso = models[best_lasso_trial]\n",
    "best_model_lasso = final_pipe_best_lasso.named_steps['regressor']\n",
    "final_pipe_best_ridge = models[best_ridge_trial]\n",
    "best_model_ridge = final_pipe_best_ridge.named_steps['regressor']\n",
    "final_pipe_best_elasticnet = models[best_elasticnet_trial]\n",
    "best_model_elasticnet = final_pipe_best_elasticnet.named_steps['regressor']\n",
    "\n",
    "# retrieve the best model object (amongst all model types evaluated)\n",
    "final_pipe_best = models[best_performing_trial.number]\n",
    "best_model = final_pipe_best.named_steps['regressor']"
   ],
   "id": "6233d4364e331135",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_pipe_best",
   "id": "f7a2a5cb76f9512d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_pipe_best.fit(X_train, y_train)",
   "id": "a7fc4a11b6e8b14e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cols_final_inputs, cols_final_output_features = proj_utils_feat_engg.get_final_features(final_pipe_best, X_train)",
   "id": "38d1696dc80f1fdb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "proj_utils_model.save_features(f'pproc_final_input_cols_{len(cols_final_inputs)}_{proj_utils.get_current_timestamp()}.csv', proj_configs.PATH_OUT_FEATURES, pd.DataFrame(cols_final_inputs))\n",
    "proj_utils_model.save_features(f'pproc_final_output_features_{len(cols_final_output_features)}_{proj_utils.get_current_timestamp()}.csv', proj_configs.PATH_OUT_FEATURES, pd.DataFrame(cols_final_output_features))"
   ],
   "id": "a22159b4cc78d7af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "proj_utils_model.save_model(f'final_pipe_{proj_utils.get_current_timestamp()}.pkl', proj_configs.PATH_OUT_MODELS, final_pipe_best)",
   "id": "65b972ae40e6a624",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_train_preds = final_pipe_best.predict(X_train)\n",
    "y_val_preds = final_pipe_best.predict(X_val)"
   ],
   "id": "bff38c8eaa4fe415",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate the model\n",
    "train_mse = mean_squared_error(y_train, y_train_preds).round(5)\n",
    "val_mse = mean_squared_error(y_val, y_val_preds).round(5)\n",
    "train_r2 = r2_score(y_train, y_train_preds).round(5)\n",
    "val_r2 = r2_score(y_val, y_val_preds).round(5)\n",
    "\n",
    "print(\"=== Model Performance ===\")\n",
    "print(f\"Train MSE: {proj_utils_plots.beautify(train_mse)}, Train R2: {proj_utils_plots.beautify(train_r2)}\")\n",
    "print(f\"Validation MSE: {proj_utils_plots.beautify(val_mse)}, Validation R2: {proj_utils_plots.beautify(val_r2)}\")"
   ],
   "id": "36fce385b777a442",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "string_to_log = f'=== Model Performance === \\n Train MSE: {train_mse}, Train R2: {train_r2} \\n Validation MSE: {val_mse}, Validation R2: {val_r2}'\n",
    "proj_utils.save_file('metrics', 'validation_metrics.txt', proj_configs.PATH_OUT_MODELS, string_to_log)"
   ],
   "id": "bcc70e6544b2a605",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d05ca7a227112434",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
